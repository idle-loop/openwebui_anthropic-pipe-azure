# ğŸš€ Anthropic API Manifold Pipe for Open WebUI

> **Advanced Anthropic Claude integration with multi-tool orchestration, prompt caching, and extended thinking capabilities**

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![Anthropic](https://img.shields.io/badge/Anthropic-Claude-orange.svg)](https://www.anthropic.com/)
[![Open WebUI](https://img.shields.io/badge/Open%20WebUI-Compatible-brightgreen.svg)](https://openwebui.com/)
[![Version](https://img.shields.io/badge/Version-0.5.4-blue.svg)](https://github.com/Podden/openwebui_anthropic_api_manifold_pipe)

---

## ğŸ“– Overview

An advanced Anthropic API integration for Open WebUI that enables Claude models to orchestrate complex multi-tool workflows. Handle sophisticated tasks like: *"Grab my Jira Issues, Research something, create a Confluence Summary for Next Meeting and send it to me via Slack!"* â€“ all in a single request with parallel tool calling and iterative refinement.

### ğŸ¯ Key Highlights

| Feature | Description |
|---------|-------------|
| ğŸ”„ **Multi-Tool Loop** | Call multiple tools iteratively in the same response |
| âš¡ **Parallel Execution** | Execute independent tools simultaneously for performance |
| ğŸ’¾ **Prompt Caching** | Automatic caching for system prompts, tools, and messages |
| ğŸ§  **Extended Thinking** | Toggle Claude's reasoning process visibility |
| ğŸ‘ï¸ **Vision Support** | Process images with automatic preprocessing |
| ğŸ’» **Code Execution** | Sandboxed Python execution via Anthropic's tool |
| ğŸ” **Web Search** | Built-in search with inline citations |
| ğŸ“Š **1M Token Context** | Extended context for Claude Sonnet 4 and 4.5 |

---

## âœ¨ Features

### Core Functionality

| Feature | Description |
|---------|-------------|
| **Anthropic Python SDK** | Official SDK integration for reliability |
| **Model Auto-Discovery** | Automatically fetches available Claude models from API |
| **Tool Call Loop** | Execute multiple tools in a single response cycle |
| **Streaming Responses** | Real-time output streaming with status updates |
| **Fine-grained Tool Streaming** | Beta streaming for progressive tool use display |
| **Comprehensive Error Handling** | Robust error recovery with retry logic |
| **Task Support** | Automatic title, tag, and follow-up generation |

### Advanced Capabilities

| Feature | Description |
|---------|-------------|
| **Image Processing/Vision** | Process and analyze images (JPEG, PNG, GIF, WebP) |
| **PDF Processing** | Base64 inline processing for PDF documents |
| **Extended Thinking** | Controllable via valve and toggle filter |
| **Effort Levels** | Configurable effort (`low`, `medium`, `high`) for Opus 4.5 |
| **Web Search Tool** | With inline citations `[1]` and source references |
| **Code Execution** | Sandboxed Python environment with result formatting |
| **Prompt Caching** | 4-level cache control for cost optimization |
| **Memory & RAG** | Intelligent cache-preserving extraction from system prompts |
| **1M Token Context** | Extended context for Sonnet 4 and 4.5 (Tier 4 required) |
| **Token Usage Display** | Context window progress bar in status |
| **Citations** | For web search and document/RAG sources |
| **OpenWebUI Compatibility** | Native function calling, Channels, Notes support |
| **Security Guards** | Duplicate tool name validation, private tool blocking |

### Supported Models

| Model | Max Tokens | Context | Thinking | 1M Context | Effort |
|-------|------------|---------|----------|------------|--------|
| Claude 3 Opus | 4,096 | 200K | âŒ | âŒ | âŒ |
| Claude 3 Sonnet | 4,096 | 200K | âŒ | âŒ | âŒ |
| Claude 3 Haiku | 4,096 | 200K | âŒ | âŒ | âŒ |
| Claude 3.5 Sonnet | 8,192 | 200K | âŒ | âŒ | âŒ |
| Claude 3.5 Haiku | 8,192 | 200K | âŒ | âŒ | âŒ |
| Claude 3.7 Sonnet | 64,000 | 200K | âœ… | âŒ | âŒ |
| Claude Sonnet 4 | 64,000 | 200K | âœ… | âœ… | âŒ |
| Claude Opus 4 | 32,000 | 200K | âœ… | âŒ | âŒ |
| Claude Opus 4.1 | 32,000 | 200K | âœ… | âŒ | âŒ |
| **Claude Sonnet 4.5** | 64,000 | 200K | âœ… | âœ… | âŒ |
| **Claude Haiku 4.5** | 64,000 | 200K | âœ… | âŒ | âŒ |
| **Claude Opus 4.5** | 64,000 | 200K | âœ… | âŒ | âœ… |

---

## ğŸ—ºï¸ Roadmap

| Status | Feature | Notes |
|--------|---------|-------|
| âœ… | **PDF Processing** | Base64 inline in messages (not Files API) |
| âœ… | **Citations** | Web search and document citations |
| âœ… | **Memory & RAG Integration** | With intelligent cache-preserving extraction |
| ğŸ“Œ | **Files API** integration | For native file handling |
| ğŸ“Œ | **UserValves API Key** support | Per-user API keys |
| ğŸ“Œ | **MCP Connector** | Pending evaluation of mcpo |
| ğŸ“Œ | **Claude Skills** | Implement Usage of Claude Skills |
| ğŸ“Œ | **Claude Memory** | Evaluate if the Claude Memory System can be hooked into Openwebui Memory |

---

## ğŸ“¦ Installation

### Option 1: Install from OpenWebUI Community (Recommended)

Install directly from the Open WebUI community:

| Component | Link |
|-----------|------|
| **Main Pipe** | [anthropic_pipe](https://openwebui.com/f/podden/anthropic_pipe) |
| **Thinking Toggle** | [anthropic_pipe_thinking_toggle](https://openwebui.com/f/podden/anthropic_pipe_thinking_toggle) |
| **Web Search Toggle** | [anthropic_web_search_toggle](https://openwebui.com/f/podden/anthropic_web_search_toggle) |
| **Code Execution Toggle** | [anthropic_pipe_code_execution_toggle](https://openwebui.com/f/podden/anthropic_pipe_code_execution_toggle) |

### Option 2: Manual Installation

1. Go to **Admin Settings** â†’ **Functions**
2. Click **"+ New Function"**
3. Copy the source code from this repository
4. Set name, ID, and description
5. Repeat for each filter

### Configuration Steps

1. **Configure API Key**: Set your Anthropic API key in the pipe settings

2. **Configure Models** (Admin Settings â†’ Models):
   - Activate the Thinking, Web Search, and Code Execution Filters for each Claude model
   - Set **Function Calling** to `Native` in Advanced Parameters
   - Deactivate OpenWebUI's built-in WebSearch and Code Interpreter (optional)

3. **Start chatting** with Claude models using advanced tool orchestration!

---

## ğŸ”§ Configuration

### Valves (Global Settings)

| Valve | Default | Description |
|-------|---------|-------------|
| `ANTHROPIC_API_KEY` | - | Your Anthropic API key (required) |
| `ENABLE_1M_CONTEXT` | `false` | Enable 1M token context window (requires Tier 4 API) |
| `WEB_SEARCH` | `true` | Enable web search tool availability |
| `MAX_TOOL_CALLS` | `15` | Maximum tool execution loops per request (1-50) |
| `MAX_RETRIES` | `3` | Maximum retries for failed requests (0-50) |
| `CACHE_CONTROL` | `disabled` | Prompt caching scope (see below) |
| `WEB_SEARCH_USER_*` | - | Default location for web searches (city, region, country, timezone) |

#### Cache Control Options

| Option | Description |
|--------|-------------|
| `cache disabled` | No caching |
| `cache tools array only` | Cache tool definitions |
| `cache tools array and system prompt` | Cache tools + system prompt |
| `cache tools array, system prompt and messages` | Full caching (recommended) |

> ğŸ’¡ **RAG & MEMORY**: The Pipe intelligently tries to extract Memories and RAG Content from the System Promt and puts it in the last User Message. While this is drasticly saving money and improving speed there maybe some problems with other filters or the models using the Knowledge or Memories wrong. Please open an issue if you have problems.

### UserValves (Per-User Settings)

| Valve | Default | Range | Description |
|-------|---------|-------|-------------|
| `ENABLE_THINKING` | `false` | - | Enable Extended Thinking mode |
| `THINKING_BUDGET_TOKENS` | `4096` | 0-32000 | Token budget for thinking |
| `EFFORT` | `high` | low/medium/high | Effort level for Opus 4.5 |
| `SHOW_TOKEN_COUNT` | `false` | - | Show context window progress bar |
| `WEB_SEARCH_MAX_USES` | `5` | 1-20 | Max searches per request |
| `WEB_SEARCH_USER_*` | - | - | Override global location settings |

### Toggle Filters

| Filter | Purpose |
|--------|---------|
| `anthropic_pipe_thinking_toggle.py` | ğŸ§  Enable thinking mode for the next message |
| `anthropic_pipe_web_search_toggle.py` | ğŸ” Force web search for the next message |
| `anthropic_pipe_code_execution_toggle.py` | ğŸ’» Enable code execution for the next message |

---

## ğŸ“ Changelog

### v0.5.4 (Latest)
- ğŸ› Fixed Message Caching Problems when using RAG or Memories

### v0.5.3
- âœ¨ Added Support for Anthropic Effort Levels (`low`, `medium`, `high`)
- âœ¨ Added Support for Opus 4.5
- ğŸ”§ Use correct logger for logging
- ğŸ—‘ï¸ Removed DEBUG Valve
- âœ¨ Introduced UserValves for user-specific settings

### v0.5.2
- ğŸ› Fixed usage statistics accumulation for multi-step tool calls
- âœ… Correctly sums input and output tokens across all turns

### v0.5.1
- ğŸ› Fixed caching issue in tool execution loops
- âš¡ Optimized caching for multi-step tool calls

### v0.5.0
- ğŸ”’ **CRITICAL FIX**: Eliminated cross-talk between concurrent users/requests
- ğŸ—‘ï¸ Removed shared instance state that caused response mixing

<details>
<summary><b>v0.4.x</b> (click to expand)</summary>

#### v0.4.9
- âš¡ Performance optimization: Moved local imports to top level
- ğŸ› Fixed fallback logic for model fetching

#### v0.4.8
- âœ¨ Added configurable `MAX_TOOL_CALLS` valve (default: 15)
- âš¡ Immediate tool execution status events
- âš ï¸ Proactive warnings when approaching tool call limit

#### v0.4.7
- ğŸ”’ Fixed potential data leakage between concurrent users

#### v0.4.6
- âœ¨ Tool results now display input parameters at the top

#### v0.4.5
- âœ¨ Added status events for local tool execution
- ğŸ¯ Better UX for long-running tools

#### v0.4.4
- âš¡ Tool calls now execute in parallel
- ğŸ› Fixed server tool identification

#### v0.4.3
- ğŸ› Fixed compatibility with OpenWebUI "Chat with Notes"

#### v0.4.2
- ğŸ› Fixed NoneType error in OpenWebUI Channels

#### v0.4.1
- âœ¨ Added token count display valve
- âœ¨ Auto-enable native function calling

#### v0.4.0
- âœ¨ Added Task Support (titles, tags, follow-ups)
- ğŸ› Fixed server + local tool use conflict

</details>

<details>
<summary><b>v0.3.x</b> (click to expand)</summary>

#### v0.3.9
- âœ¨ Added fine-grained cache control valve (4 levels)

#### v0.3.8
- ğŸ—‘ï¸ Removed MAX_OUTPUT_TOKENS valve
- âš¡ Reworked caching with OpenWebUI Memory System
- âœ¨ Added retry logic for transient errors

#### v0.3.7
- ğŸ› Fixed Extended Thinking compatibility with Tool Use

#### v0.3.6
- âœ¨ Added Claude 4.5 Haiku Model

#### v0.3.5
- ğŸ› Fixed last chunk not sent bug
- âœ¨ Added correct citation handling for Web Search

#### v0.3.4
- âœ¨ Added Claude 4.5 Sonnet support
- âœ¨ Added OpenWebUI token usage compatibility
- ğŸ”’ Added duplicate tool name validation

#### v0.3.3 - v0.3.1
- Various bug fixes

#### v0.3.0 (September 2025)
- âœ¨ Added Vision support
- âœ¨ Added Extended Thinking filter
- âœ¨ Added Web Search enforcement toggle
- âœ¨ Added Anthropic Code Execution Tool
- âš¡ Improved cache control with dynamic Memory/RAG detection
- âœ¨ Added 1M context beta header for Sonnet 4

</details>

<details>
<summary><b>v0.2.0</b> (August 2025)</summary>

- ğŸ› Fixed caching by moving Memories to Messages
- âœ¨ Cache usage statistics display
- ğŸ› Fixed last chunk not showing in frontend
- âœ¨ Implemented Web Search valves and error handling
- âœ¨ Added Cache_Control for System_Prompt, Tools, and Messages

</details>

---

## ğŸ¤ Contributing

Bug reports and feature requests are welcome! Feel free to [open an issue](https://github.com/Podden/openwebui_anthropic_api_manifold_pipe/issues) if you encounter any problems.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built for [Open WebUI](https://github.com/open-webui/open-webui)
- Powered by [Anthropic Claude](https://www.anthropic.com/)
- Thanks Balaxxe and nbellochi for their original Pipe
---